{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build BreastCancerNet Convolutional Neural Network (CNN) in PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to build CancerNet convolutional neural network the PyTorch way. I took the breast cancer prediction CNN map from here - https://pyimagesearch.com/wp-content/uploads/2019/02/cancernet_arch_raw.png. \n",
    "\n",
    "First PyTorch imports are listed on *Lines 2-\n",
    "\n",
    "Let’s go ahead and define the BreastCancerNet class on Line 12 and then proceed to build it on Line 14.\n",
    "\n",
    "The build  method requires four parameters:\n",
    "\n",
    "width , height , and depth : Here we specify the input image volume shape to our network, where depth  is the number of color channels each image contains.\n",
    "\n",
    "classes : The number of classes our network will predict (for BreastCancerNet , it will be 2 ).\n",
    "We go ahead and initialize our model  on Line 17 and subsequently, specify our inputShape  (Line 18). In the case of using TensorFlow as our backend, we’re now ready to add layers.\n",
    "\n",
    "Other backends that specify \"channels_first\"  require that we place the depth  at the front of the inputShape  and image dimensions following (Lines 23-24).\n",
    "\n",
    "We use the Sequential API to build BreastCancerNet and Conv2D to implement depthwise convolutions. The class BreastCancerNet has a static method build that takes four parameters- width and height of the image, its depth (the number of color channels in each image), and the number of classes the network will predict between, which, for us, is 2 (0 and 1).\n",
    "\n",
    "In this method, we initialize model and shape. When using channels_first, we update the shape and the channel dimension.\n",
    "\n",
    "Now, we’ll define three DEPTHWISE_CONV => RELU => POOL layers; each with a higher stacking and a greater number of filters. The softmax classifier outputs prediction percentages for each class. In the end, we return the model.\n",
    "\n",
    "Three DEPTHWISE_CONV => RELU => POOL  blocks are defined here with increasing stacking and number of filters. I’ve applied BatchNormalization  and Dropout  as well.\n",
    "\n",
    "Let’s append our fully connected head:\n",
    "\n",
    "Our FC => RELU  layers and softmax classifier make the head of the network.\n",
    "\n",
    "The output of the softmax classifier will be the prediction percentages for each class our model will predict.\n",
    "\n",
    "Finally, our model  is returned to the training script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages \n",
    "\n",
    "#container\n",
    "from torch.nn import Sequential\n",
    "from torch.nn import Module\n",
    "\n",
    "#convolution layers\n",
    "from torch.nn import Conv2d\n",
    "\n",
    "#pooling layers\n",
    "from torch.nn import MaxPool2d\n",
    "\n",
    "#Activations\n",
    "from torch.nn import ReLU\n",
    "from torch.nn import Softmax\n",
    "\n",
    "#normalization layers\n",
    "from torch.nn import BatchNorm2d\n",
    "\n",
    "#Linear Layers\n",
    "from torch.nn import Linear\n",
    "\n",
    "#Dropout layers\n",
    "from torch.nn import Dropout\n",
    "\n",
    "#loss function \n",
    "from torch.nn import CrossEntropyLoss \n",
    "#This criterion combines nn.LogSoftmax() and nn.NLLLoss() in one single class.\n",
    "\n",
    "#Utility functions\n",
    "from torch.nn import Flatten\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Build CNN BreastCancerNet in PyTorch\n",
    "#Adopted from CancerNet model in Keras by DataFlair Team\n",
    "\n",
    "class BreastCancerNet(Module):\n",
    "    def __init__(self):\n",
    "        super(BreastCancerNet, self).__init__()\n",
    "       \n",
    "    def build(width, height, depth, classes):\n",
    "        model=Sequential()\n",
    "        shape=(height, width, depth)\n",
    "        \n",
    "        if K.image_data_format() == 'channels_first':\n",
    "            shape=(depth,height,width)\n",
    "        \n",
    "       # Declare all the layers for feature extraction\n",
    "        self.features = Sequential(Conv2d(in_channels=3,\n",
    "                                          out_channels=32,\n",
    "                                          kernel_size = (3, 3), \n",
    "                                          padding=1, input_shape=shape),\n",
    "                                   ReLU(inplace=True),\n",
    "                                   BatchNorm2d(32),\n",
    "                                   MaxPool2d(3,3),\n",
    "                                   Dropout(0.23),\n",
    "                                   Conv2d(in_channels=32, \n",
    "                                          out_channels=64, \n",
    "                                          kernel_size = (3, 3), \n",
    "                                          padding=1),\n",
    "                                   ReLU(inplace=True),\n",
    "                                   BatchNorm2d(64),\n",
    "                                   MaxPool2d(3,3),\n",
    "                                   Dropout(0.25),\n",
    "                                   Conv2d(in_channels=64, \n",
    "                                          out_channels=128, \n",
    "                                          kernel_size = (3, 3), \n",
    "                                          padding=1),\n",
    "                                   ReLU(inplace=True),\n",
    "                                   BatchNorm2d(128),\n",
    "                                   MaxPool2d(3,3),\n",
    "                                   Dropout(0.25))\n",
    "        \n",
    "                                   \n",
    "        # Declare all the layers for classification (fully connected layers)\n",
    "        self.classifier = Sequential(\n",
    "            Linear(128*6*6, 6912),\n",
    "            ReLU(inplace=True),\n",
    "            Dropout(0.5),\n",
    "            Linear(6912, 6912),\n",
    "            ReLU(inplace=True),\n",
    "            Linear(6912, 2)\n",
    "        \n",
    "        #self._initialize_weights()\n",
    "                 \n",
    "    def  forward(self, x): \n",
    "                 #Apply the feature extract in the input\n",
    "                 x = self.features(x)\n",
    "                 #squeeze the three spatial dimenstions in one \n",
    "                 x = x.view(-1, 128*6*6)\n",
    "                 x = self.classifier(x)\n",
    "                 return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
