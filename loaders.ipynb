{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we declare the path to the input dataset (datasets/original). A Breast Cancer Histology Image Dataset from kaggle: https://www.kaggle.com/paultimothymooney/breast-histopathology-images/source "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.chdir('C:\\\\Users\\\\abebu\\\\Dropbox\\\\Data Science\\\\DeepLearning\\\\Capstone Project 2\\\\breast-cancer-classification')\n",
    "mkdir datasets\\original"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we copy the downloaded dataset to the datasets/origianl folder, we declare the path for the new directory (datasets/idc), and the paths for the training, validation, and testing directories using the base path. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 40\n",
    "BS = 32\n",
    "LEARNING_RATE = 1e-2\n",
    "INPUT_DATASET = 'datasets\\original'\n",
    "BASE_PATH = 'datasets/idc'\n",
    "TRAIN_PATH = os.path.sep.join([BASE_PATH, 'training'])\n",
    "VAL_PATH = os.path.sep.join([BASE_PATH, 'validation'])\n",
    "TEST_PATH = os.path.sep.join([BASE_PATH, 'testing'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also declare that 80% of the entire dataset will be used for training, and of that, 10% will be used for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SPLIT = 0.8\n",
    "VAL_SPLIT = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we’ll import from config, imutils, random, shutil, and os. `config` settings and `paths` to build a list of original paths to the images, then we use `random` to randomly shuffle our paths, `shutil` to copy images, and `os` for joining paths and making directories (*Lines 1-3*)\n",
    "\n",
    "Then we will grab all the `originalPaths` for our dataset and randomly suffle them (*Lines 5-7*). \n",
    "\n",
    "Then, we calculate an `index` by multiplying the length of this list by 0.8 so we can slice this list to get sublists for the training and testing datasets (*Lines 9-11*). Next, we further calculate an index saving 10% of the list for the training dataset for validation (`valPaths`)(*Line 14*) and keeping the rest for training itself (`trainPaths`) (*Line 15*).\n",
    "\n",
    "*Lines 17-20* defines a list with tuples called `datasets`. Inside are three tuples, each with the information required to organize all of our `originalPaths` into training, validation, and testing sets. These hold the paths and the base path for each. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from breastcancernet import config\n",
    "from imutils import paths\n",
    "import random, shutil\n",
    "\n",
    "originalPaths=list(paths.list_images(config.INPUT_DATASET))\n",
    "random.seed(7)\n",
    "random.shuffle(originalPaths)\n",
    "\n",
    "index=int(len(originalPaths)*config.TRAIN_SPLIT)\n",
    "trainPaths=originalPaths[:index]\n",
    "testPaths=originalPaths[index:]\n",
    "\n",
    "index=int(len(trainPaths)*config.VAL_SPLIT)\n",
    "valPaths=trainPaths[:index]\n",
    "trainPaths=trainPaths[index:]\n",
    "\n",
    "datasets= [('training', trainPaths, config.TRAIN_PATH),\n",
    "          ('validation', valPaths, config.VAL_PATH),\n",
    "          ('testing', testPaths, config.TEST_PATH)\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing idc Datasets in PyTorch \n",
    "\n",
    "Load image data using `datasets.ImageFolder` from `torchvision`\n",
    "I import `matplotlib.pyplot` as `plt` where matplotlib is a 2D Plotting library for displaying image as well as I import `torch` and `datasets` and `transforms` from `torchvision` and `helper` module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "`Transform` using `ImageFolder` as\n",
    "dataset = datasets.ImageFolder('path', transform=transform)\n",
    "where ‘path’ is the path to the data set which the path to the folder where the data is present and while loading data with ImageFolder we need to define some transforms because images are of different sizes and shape and we need all image in training set to be of the same size for training. Therefore we define resize with transform.Resize() or crop with transforms.CenterCrop(), transforms.RandomResizedCrop() also we need to convert all the image to PyTorch tensors for this purpose we use transforms.ToTensor(). Also, we will combine this transforms to pipeline with transforms.Compose(), which run the list of transforms in sequence.\n",
    "\n",
    "`Data Loaders`\n",
    "After loaded ImageFolder, we have to pass it to DataLoader. It takes a dataset and returns batches of images and corresponding labels. Here we can set batch_size and shuffle (True/False) after each epoch. For this we need to pass dataset, batch_size, shuffle into torch.utils.data.DataLoader()\n",
    "\n",
    "`Testing Data Loader`\n",
    "Here, data loader is a generator and to get data out of it, we need to loop through it or convert it to an iterator and call next()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we loop over the `datasets` list.\n",
    "\n",
    "For each `setType`, `originalPaths`, and `basePath` in this list, we’ll print, say, ‘Building testing set’. If the base path does not exist, we’ll create the base output directory (*Lines 1-6*).  \n",
    "\n",
    "And for each path in `originalPaths`, we'll implement a nested loop over all input images in the current split (*Line 8*), we’ll extract the `file` name from the input path (*Line 9*) and then extract the class `label` from the `file` (*Line 10*). We’ll build the output path (`labelPath`)to the label directory(0 or 1)- if it doesn’t exist yet, we’ll explicitly create this directory (*Lines 12-15*). Finally, we’ll build the path to the resulting image and copy the image into its destination- where it belongs (*Lines 17 and 19*). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building training set\n",
      "Building directory datasets/idc\\training\n",
      "Building directory datasets/idc\\training\\0\n",
      "Building directory datasets/idc\\training\\1\n",
      "Building validation set\n",
      "Building directory datasets/idc\\validation\n",
      "Building directory datasets/idc\\validation\\0\n",
      "Building directory datasets/idc\\validation\\1\n",
      "Building testing set\n",
      "Building directory datasets/idc\\testing\n",
      "Building directory datasets/idc\\testing\\0\n",
      "Building directory datasets/idc\\testing\\1\n"
     ]
    }
   ],
   "source": [
    "for (setType, originalPaths, basePath) in datasets:\n",
    "    print(f'Building {setType} set')\n",
    "    \n",
    "    if not os.path.exists(basePath):\n",
    "        print(f'Building directory {basePath}')\n",
    "        os.makedirs(basePath)\n",
    "        \n",
    "    for path in originalPaths:\n",
    "        file=path.split(os.path.sep)[-1]\n",
    "        label=file[-5:-4]\n",
    "        \n",
    "        labelPath=os.path.sep.join([basePath, label])\n",
    "        if not os.path.exists(labelPath):\n",
    "            print(f'Building directory {labelPath}')\n",
    "            os.makedirs(labelPath)\n",
    "            \n",
    "        newPath=os.path.sep.join([labelPath, file])\n",
    "        shutil.copy2(path, newPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import torch\n",
    "import torch.utils.data as data \n",
    "import torchvision\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8023, 0.6129, 0.7238])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First i want to calculate mean and standard deviation of my training set\n",
    "# to get the values for transforms.Normalize\n",
    "\n",
    "traindata=datasets.ImageFolder(config.TRAIN_PATH, transform=transforms.ToTensor())\n",
    "image_means =torch.stack([t.mean(1).mean(1) for t, c in traindata])\n",
    "image_means.mean(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0158, 0.0219, 0.0178])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_stds =torch.stack([t.std(1).std(1) for t, c in traindata])\n",
    "image_stds.std(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the data to torch tensors and normalize it \n",
    "\n",
    "transform_idc = transforms.Compose([transforms.RandomResizedCrop(48),\n",
    "                                      transforms.RandomHorizontalFlip(),\n",
    "                                      transforms.RandomVerticalFlip(),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize(mean=[0.8023, 0.6129, 0.7238], \n",
    "                                                           std=[0.0158, 0.0219, 0.0178])]) \n",
    "\n",
    "\n",
    "# Prepare training set, validation set and testing set\n",
    "trainset = datasets.ImageFolder(config.TRAIN_PATH, transform=transform_idc)\n",
    "valset = datasets.ImageFolder(config.VAL_PATH, transform=transform_idc)\n",
    "testset = datasets.ImageFolder(config.TEST_PATH, transform=transform_idc )\n",
    "\n",
    "#parameters \n",
    "params = {'batch_size': 32,\n",
    "          'shuffle': True,\n",
    "          'num_workers': 4}\n",
    "\n",
    "# Prepare training loader and testing loader (makes datasets iterable)\n",
    "\n",
    "trainloader = data.DataLoader(trainset, **params)\n",
    "valloader = data.DataLoader(valset, **params)\n",
    "testloader = data.DataLoader(testset, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
